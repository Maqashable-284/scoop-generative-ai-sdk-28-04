"""
Scoop GenAI - Google Gemini SDK Implementation
==============================================

Production-ready FastAPI server with:
- Gemini 2.5 Flash integration
- MongoDB persistence
- SSE streaming
- Automatic function calling
- Comprehensive error handling

ANSWERS TO ALL QUESTIONS:

Question #4: Technical Implementation
-------------------------------------
- Async Support: send_message_async() is production-stable
- Streaming: Use send_message(..., stream=True) or generate_content_async(stream=True)
- Error Handling: See GEMINI_EXCEPTIONS below
- Auto Function Calling: Model retries with different params if tool returns error

Question #5: Production Considerations
--------------------------------------
- Cloud Run: Cold start ~2-3s (SDK import), use min_instances=1
- Observability: Google Cloud Trace integration shown below
- Rate Limits: 2000 RPM (paid), 15 RPM (free)
- Retry: Exponential backoff on 429/503

Question #6: Security
---------------------
- Prompt Injection: Use SafetySettings (shown below)
- PII: MongoDB encryption at rest recommended
"""
import os
import re
import asyncio
import logging
from datetime import datetime, timedelta
from typing import Optional, Dict, Any, AsyncIterator
from contextlib import asynccontextmanager
from dataclasses import dataclass, field
import uuid

# Note: nest_asyncio removed due to uvloop conflict in Python 3.13
# Async loop warnings in user_tools.py are non-critical - app continues to work

# Prompt injection detection patterns (logging only, no blocking)
SUSPICIOUS_PATTERNS = [
    'ignore previous', 'forget instructions', 'disregard', 'override system',
    'system prompt', 'ignore above', 'new instructions', 'you are now'
]

# FastAPI
from fastapi import FastAPI, HTTPException, Request, Depends, Header
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse
from pydantic import BaseModel, Field, field_validator

# Google Generative AI
import google.generativeai as genai
from google.generativeai.types import (
    HarmCategory,
    HarmBlockThreshold,
    GenerationConfig,
    ContentDict,
)

# Local imports
from config import settings, SYSTEM_PROMPT
from app.memory.mongo_store import (
    db_manager,
    ConversationStore,
    UserStore,
)
from app.catalog.loader import CatalogLoader
from app.tools.user_tools import (
    get_user_profile,
    update_user_profile,
    search_products,
    get_product_details,
    set_stores,
    GEMINI_TOOLS,
)

# Rate Limiting
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)

# =============================================================================
# LOGGING & OBSERVABILITY
# =============================================================================

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# Question #5: Observability - Google Cloud Trace Integration
# Uncomment for Cloud Run deployment:
# from opentelemetry import trace
# from opentelemetry.exporter.cloud_trace import CloudTraceSpanExporter
# from opentelemetry.sdk.trace import TracerProvider
# from opentelemetry.sdk.trace.export import BatchSpanProcessor
#
# trace.set_tracer_provider(TracerProvider())
# cloud_trace_exporter = CloudTraceSpanExporter()
# trace.get_tracer_provider().add_span_processor(
#     BatchSpanProcessor(cloud_trace_exporter)
# )
# tracer = trace.get_tracer(__name__)


# =============================================================================
# GEMINI CONFIGURATION
# =============================================================================

# Initialize Gemini
genai.configure(api_key=settings.gemini_api_key)

# Question #6: Security - Safety Settings
SAFETY_SETTINGS = {
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
}

# Generation config - max_output_tokens from settings for Gemini 3 compatibility
GENERATION_CONFIG = GenerationConfig(
    temperature=0.7,
    top_p=0.95,
    top_k=40,
    max_output_tokens=settings.max_output_tokens,  # Default 4096 for longer responses
)


# =============================================================================
# EXCEPTION HANDLING
# =============================================================================

"""
ANSWER TO QUESTION #4: Error Handling - Gemini SDK Exceptions

Common exceptions to catch:
1. google.api_core.exceptions.ResourceExhausted (429) - Rate limit
2. google.api_core.exceptions.ServiceUnavailable (503) - Service down
3. google.api_core.exceptions.InvalidArgument (400) - Bad request
4. google.generativeai.types.BlockedPromptException - Safety filter
5. google.generativeai.types.StopCandidateException - Generation stopped
"""

RETRY_EXCEPTIONS = (
    "ResourceExhausted",  # 429 - Rate limit
    "ServiceUnavailable",  # 503 - Temporary outage
    "DeadlineExceeded",  # Timeout
)


class GeminiTimeoutError(Exception):
    """Raised when Gemini API call times out"""
    pass


async def call_with_retry(
    func,
    *args,
    max_retries: int = 4,
    base_delay: float = 2.0,
    **kwargs
):
    """
    ANSWER TO QUESTION #5: Retry Logic for 429 errors

    Exponential backoff: 2s, 4s, 8s, 16s
    Now wrapped with timeout for Gemini 3 compatibility.
    """
    last_exception = None

    for attempt in range(max_retries):
        try:
            # Wrap with timeout for Gemini 3 compatibility
            return await asyncio.wait_for(
                func(*args, **kwargs),
                timeout=settings.gemini_timeout_seconds
            )
        except asyncio.TimeoutError:
            raise GeminiTimeoutError(
                f"Gemini API timed out after {settings.gemini_timeout_seconds}s"
            )
        except Exception as e:
            error_type = type(e).__name__

            if error_type in RETRY_EXCEPTIONS:
                delay = base_delay * (2 ** attempt)
                logger.warning(
                    f"Retry {attempt + 1}/{max_retries} after {error_type}, "
                    f"waiting {delay}s"
                )
                await asyncio.sleep(delay)
                last_exception = e
            else:
                raise

    raise last_exception


# =============================================================================
# SESSION MANAGEMENT
# =============================================================================

@dataclass
class Session:
    """Chat session with Gemini model"""
    user_id: str
    session_id: str
    chat: Any  # genai.ChatSession
    created_at: datetime = field(default_factory=datetime.utcnow)
    last_activity: datetime = field(default_factory=datetime.utcnow)

    def update_activity(self):
        self.last_activity = datetime.utcnow()


class SessionManager:
    """
    Manages chat sessions per user

    ANSWER TO QUESTION #1: Multi-session Support

    - Each user gets persistent session
    - Sessions persist in MongoDB
    - In-memory cache for active sessions
    - TTL-based cleanup
    """

    def __init__(
        self,
        model: genai.GenerativeModel,
        conversation_store: ConversationStore,
        user_store: UserStore,
        catalog_context: str = "",
        ttl_seconds: int = 3600
    ):
        self.model = model
        self.conversation_store = conversation_store
        self.user_store = user_store
        self.catalog_context = catalog_context
        self.ttl = timedelta(seconds=ttl_seconds)
        self._sessions: Dict[str, Session] = {}
        self._lock = asyncio.Lock()

    async def get_or_create_session(self, user_id: str, session_id: Optional[str] = None) -> Session:
        """Get existing session or create new one
        
        Args:
            user_id: The user identifier
            session_id: Optional specific session ID for multi-conversation support
        """
        # Use session_id as cache key if provided, otherwise use user_id
        cache_key = session_id if session_id else user_id
        
        async with self._lock:
            # Check in-memory cache
            if cache_key in self._sessions:
                session = self._sessions[cache_key]
                session.update_activity()
                return session

            # Load from MongoDB
            history, loaded_session_id, summary = await self.conversation_store.load_history(
                user_id, 
                session_id=session_id
            )
            
            # Use provided session_id or auto-generated one
            final_session_id = session_id if session_id else loaded_session_id

            # Convert BSON history to Gemini format
            gemini_history = self.conversation_store.bson_to_gemini(history)

            # Create chat session
            chat = self.model.start_chat(
                history=gemini_history,
                enable_automatic_function_calling=True
            )

            # If we have a summary from pruned history, inject it
            if summary and not history:
                # Add summary as context
                logger.info(f"Injecting summary for {user_id}: {summary[:100]}...")

            session = Session(
                user_id=user_id,
                session_id=final_session_id,
                chat=chat
            )

            self._sessions[cache_key] = session
            return session

    async def save_session(self, session: Session) -> None:
        """Save session to MongoDB"""
        # Get user profile for metadata
        user = await self.user_store.get_user(session.user_id)

        metadata = {
            "language": "ka",
            "last_topic": None,
            "products_viewed": [],
            "products_recommended": []
        }

        await self.conversation_store.save_history(
            user_id=session.user_id,
            session_id=session.session_id,
            history=session.chat.history,
            metadata=metadata
        )

    async def clear_session(self, user_id: str) -> bool:
        """Clear user session"""
        async with self._lock:
            if user_id in self._sessions:
                session = self._sessions.pop(user_id)
                await self.conversation_store.clear_session(session.session_id)
                return True
            return False

    async def cleanup_stale_sessions(self) -> int:
        """Remove expired sessions"""
        now = datetime.utcnow()
        expired = []

        async with self._lock:
            for user_id, session in self._sessions.items():
                if now - session.last_activity > self.ttl:
                    # Save before removing
                    await self.save_session(session)
                    expired.append(user_id)

            for user_id in expired:
                del self._sessions[user_id]

        logger.info(f"Cleaned up {len(expired)} stale sessions")
        return len(expired)


# =============================================================================
# GLOBAL INSTANCES
# =============================================================================

conversation_store = ConversationStore(
    max_messages=settings.max_history_messages,
    max_tokens=settings.max_history_tokens
)
user_store = UserStore()
catalog_loader: Optional[CatalogLoader] = None
session_manager: Optional[SessionManager] = None


# =============================================================================
# FASTAPI APP
# =============================================================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan manager"""
    global catalog_loader, session_manager

    # Startup
    logger.info("Starting Scoop GenAI server...")

    # Connect to MongoDB
    if settings.mongodb_uri:
        await db_manager.connect(
            settings.mongodb_uri,
            settings.mongodb_database
        )

    # Initialize catalog loader
    catalog_loader = CatalogLoader(
        db=db_manager.db if settings.mongodb_uri else None,
        cache_ttl_seconds=settings.catalog_cache_ttl_seconds
    )

    # Load catalog context
    catalog_context = await catalog_loader.get_catalog_context()
    logger.info(f"Loaded catalog: ~{len(catalog_context)//4} tokens")

    # Create Gemini model with tools
    # ANSWER TO QUESTION #4: Automatic Function Calling Setup
    model = genai.GenerativeModel(
        model_name=settings.model_name,
        tools=GEMINI_TOOLS,
        system_instruction=SYSTEM_PROMPT + "\n\n" + catalog_context,
        safety_settings=SAFETY_SETTINGS if settings.enable_safety_settings else None,
        generation_config=GENERATION_CONFIG,
    )

    # Set up tool stores with sync client for avoiding async loop conflicts
    # FIX: Gemini function calling runs sync, so we need sync MongoDB client
    from pymongo import MongoClient
    sync_db = None
    if settings.mongodb_uri:
        sync_client = MongoClient(settings.mongodb_uri)
        sync_db = sync_client[settings.mongodb_database]
        logger.info("Initialized sync MongoDB client for tool functions")
    
    set_stores(
        user_store=user_store,
        db=db_manager.db if settings.mongodb_uri else None,
        sync_db=sync_db
    )

    # Initialize session manager
    session_manager = SessionManager(
        model=model,
        conversation_store=conversation_store,
        user_store=user_store,
        catalog_context=catalog_context,
        ttl_seconds=settings.session_ttl_seconds
    )

    # Start cleanup task
    cleanup_task = asyncio.create_task(cleanup_loop())

    yield

    # Shutdown
    logger.info("Shutting down...")
    cleanup_task.cancel()
    try:
        await cleanup_task
    except asyncio.CancelledError:
        pass

    # Save all active sessions
    for user_id, session in session_manager._sessions.items():
        await session_manager.save_session(session)

    await db_manager.disconnect()


async def cleanup_loop():
    """Background task to clean up stale sessions"""
    while True:
        await asyncio.sleep(300)  # 5 minutes
        if session_manager:
            await session_manager.cleanup_stale_sessions()


app = FastAPI(
    title="Scoop GenAI",
    description="Sports Nutrition AI Consultant (Gemini SDK)",
    version="1.0.0",
    lifespan=lifespan
)

# CORS - Security: Validate configuration
cors_origins = settings.allowed_origins.split(",")
if "*" in cors_origins and not settings.debug:
    logger.warning(
        "⚠️ SECURITY: CORS allows all origins (*) in production mode! "
        "Set ALLOWED_ORIGINS env var to restrict access."
    )

app.add_middleware(
    CORSMiddleware,
    allow_origins=cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Rate Limiting
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)


# =============================================================================
# REQUEST/RESPONSE MODELS
# =============================================================================

class ChatRequest(BaseModel):
    user_id: str = Field(..., min_length=1, max_length=128)
    message: str = Field(..., min_length=1, max_length=4000)
    session_id: Optional[str] = Field(None, max_length=128)  # For multi-conversation support

    @field_validator('user_id')
    @classmethod
    def validate_user_id(cls, v: str) -> str:
        import re
        if not re.match(r'^[a-zA-Z0-9_-]+$', v):
            raise ValueError('Invalid user_id format - only alphanumeric, underscore, and dash allowed')
        return v

    @field_validator('message')
    @classmethod
    def validate_message(cls, v: str) -> str:
        if not v.strip():
            raise ValueError('Message cannot be empty or whitespace only')
        return v.strip()


class ChatResponse(BaseModel):
    response_text_geo: str
    current_state: str = "CHAT"
    quick_replies: list = []
    picked_product_ids: list = []
    carousel: Optional[dict] = None
    success: bool = True
    error: Optional[str] = None


# =============================================================================
# ADMIN AUTHENTICATION
# =============================================================================

async def verify_admin_token(x_admin_token: str = Header(None)) -> bool:
    """Verify admin token for protected endpoints"""
    if not settings.admin_token:
        # If no admin token configured, block access entirely
        raise HTTPException(status_code=403, detail="Admin access not configured")
    if x_admin_token != settings.admin_token:
        raise HTTPException(status_code=403, detail="Invalid admin token")
    return True


# =============================================================================
# QUICK REPLIES PARSER
# =============================================================================

def parse_quick_replies(text: str) -> tuple[str, list]:
    """
    Extract quick replies from response text
    
    Primary format:
    [QUICK_REPLIES]
    Option 1
    Option 2
    [/QUICK_REPLIES]
    
    Fallback format (if primary not found):
    **შემდეგი ნაბიჯი:**
    - Option 1
    - Option 2
    """
    # First: Clean up any leaked function call XML/code
    # Gemini sometimes outputs function calls as text instead of proper API calls
    text = clean_leaked_function_calls(text)
    
    # Primary: Look for [QUICK_REPLIES] tag
    pattern = r'\[QUICK_REPLIES\](.*?)\[/QUICK_REPLIES\]'
    match = re.search(pattern, text, re.DOTALL)

    if match:
        quick_text = match.group(1).strip()
        quick_replies = [
            {"title": line.strip(), "payload": line.strip()}
            for line in quick_text.split("\n")
            if line.strip()
        ]
        clean_text = re.sub(pattern, '', text, flags=re.DOTALL).strip()
        return clean_text, quick_replies
    
    # Fallback: Look for "შემდეგი ნაბიჯი:" section with bullet points
    fallback_pattern = r'\*?\*?შემდეგი ნაბიჯი:?\*?\*?\s*\n+((?:[-•*]\s*.+\n?)+)'
    fallback_match = re.search(fallback_pattern, text, re.IGNORECASE)
    
    if fallback_match:
        bullet_text = fallback_match.group(1).strip()
        quick_replies = []
        
        for line in bullet_text.split("\n"):
            # Remove bullet point prefix (-, •, *)
            clean_line = re.sub(r'^[-•*]\s*', '', line.strip())
            if clean_line:
                quick_replies.append({
                    "title": clean_line,
                    "payload": clean_line
                })
        
        if quick_replies:
            # Remove the "შემდეგი ნაბიჯი:" section from display text
            clean_text = re.sub(fallback_pattern, '', text, flags=re.IGNORECASE).strip()
            return clean_text, quick_replies
    
    # No quick replies found
    return text, []


def clean_leaked_function_calls(text: str) -> str:
    """
    Remove any leaked function call XML/code from Gemini response.
    
    Gemini sometimes outputs function calls as text instead of using
    the proper function calling API. This cleans up those artifacts.
    """
    # Remove <execute_function.../> tags
    text = re.sub(r'<execute_function[^>]*/?>', '', text, flags=re.IGNORECASE | re.DOTALL)
    
    # Remove print(...) statements that look like function calls
    text = re.sub(r'print\([^)]+\)', '', text)
    
    # Remove any remaining XML-like function tags
    text = re.sub(r'</?[a-z_]+[^>]*>', '', text, flags=re.IGNORECASE)
    
    # Clean up multiple newlines
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    return text.strip()


# =============================================================================
# ENDPOINTS
# =============================================================================

@app.get("/")
async def root():
    """Root endpoint"""
    return {
        "service": "Scoop GenAI",
        "version": "1.0.0",
        "model": settings.model_name,
        "status": "running"
    }


@app.get("/health")
async def health():
    """Health check endpoint"""
    db_status = await db_manager.ping() if settings.mongodb_uri else True
    return {
        "status": "healthy" if db_status else "degraded",
        "database": "connected" if db_status else "disconnected",
        "model": settings.model_name
    }


@app.post("/chat", response_model=ChatResponse)
@limiter.limit(f"{settings.rate_limit_per_minute}/minute")
async def chat(request: Request, chat_request: ChatRequest):
    """
    Main chat endpoint

    ANSWER TO QUESTION #4: Async Support
    - send_message_async() is production-stable
    - Automatic function calling handles tool execution
    """
    try:
        # Get or create session (with optional session_id for multi-conversation support)
        session = await session_manager.get_or_create_session(
            chat_request.user_id, 
            session_id=chat_request.session_id
        )

        # Prompt injection detection (logging only, no blocking)
        message_lower = chat_request.message.lower()
        if any(pattern in message_lower for pattern in SUSPICIOUS_PATTERNS):
            logger.warning(f"Possible prompt injection detected: {chat_request.message[:100]}")

        # Send message with retry
        # ANSWER TO QUESTION #4: Error handling with retry
        response = await call_with_retry(
            session.chat.send_message_async,
            chat_request.message
        )

        # Extract text safely (Gemini 3 may return empty response)
        try:
            response_text = response.text
        except ValueError as e:
            # Gemini returned empty response - provide fallback
            logger.warning(f"Empty Gemini response for user {chat_request.user_id}: {e}")
            return ChatResponse(
                response_text_geo=(
                    "სამწუხაროდ, პასუხის გენერირება ვერ მოხერხდა. "
                    "გთხოვთ სცადოთ მარტივი კითხვა."
                ),
                quick_replies=[
                    {"title": "რა არის კრეატინი?", "payload": "რა არის კრეატინი?"},
                    {"title": "რომელი პროტეინი ჯობია?", "payload": "რომელი პროტეინი ჯობია?"},
                ],
                success=False,
                error="empty_response"
            )

        # Parse quick replies
        clean_text, quick_replies = parse_quick_replies(response_text)

        # Save session
        await session_manager.save_session(session)

        # Update user stats
        await user_store.increment_stats(chat_request.user_id)

        return ChatResponse(
            response_text_geo=clean_text,
            quick_replies=quick_replies,
            success=True
        )

    except GeminiTimeoutError as e:
        # Gemini 3 compatibility: Handle timeout gracefully
        logger.warning(f"Gemini timeout for user {chat_request.user_id}: {e}")
        return ChatResponse(
            response_text_geo=(
                "კითხვა ძალიან რთულია და დამუშავებას დიდი დრო სჭირდება. "
                "გთხოვთ დაყავით რამდენიმე მარტივ კითხვად. "
                "მაგალითად: ჯერ იკითხეთ პროტეინზე, შემდეგ კრეატინზე."
            ),
            quick_replies=[
                {"title": "რომელი პროტეინი ჯობია ვეგეტარიანელისთვის?", "payload": "რომელი პროტეინი ჯობია ვეგეტარიანელისთვის?"},
                {"title": "რა ღირს კრეატინი?", "payload": "რა ღირს კრეატინი?"},
            ],
            success=False,
            error="timeout"
        )

    except Exception as e:
        # Generate error ID for log correlation
        error_id = uuid.uuid4().hex[:8]
        logger.error(f"Chat error [{error_id}]: {e}", exc_info=True)

        # Check for safety block
        error_type = type(e).__name__
        if "Blocked" in error_type:
            return ChatResponse(
                response_text_geo="ბოდიში, ეს კითხვა ვერ დამუშავდა. სცადეთ სხვანაირად.",
                success=False,
                error="content_blocked"
            )

        return ChatResponse(
            response_text_geo="დაფიქსირდა შეცდომა. გთხოვთ სცადოთ თავიდან.",
            success=False,
            error=f"internal_error:{error_id}"  # Safe: only error ID, not details
        )


@app.post("/chat/stream")
@limiter.limit(f"{settings.rate_limit_per_minute}/minute")
async def chat_stream(request: Request, stream_request: ChatRequest):
    """
    SSE Streaming endpoint

    ANSWER TO QUESTION #4: Streaming with Gemini SDK

    Claude streaming:
        for chunk in response:
            yield chunk.text

    Gemini streaming:
        response = await chat.send_message_async(msg, stream=True)
        async for chunk in response:
            yield chunk.text
    """
    async def generate():
        try:
            session = await session_manager.get_or_create_session(stream_request.user_id)

            # Stream response
            response = await session.chat.send_message_async(
                stream_request.message,
                stream=True
            )

            full_text = ""

            # ANSWER TO QUESTION #4: Streaming iteration
            async for chunk in response:
                if chunk.text:
                    full_text += chunk.text
                    # SSE format
                    yield f"data: {chunk.text}\n\n"

            # Parse quick replies from full response
            clean_text, quick_replies = parse_quick_replies(full_text)

            # Send quick replies as final event
            if quick_replies:
                import json
                yield f"event: quick_replies\ndata: {json.dumps(quick_replies)}\n\n"

            # Save session
            await session_manager.save_session(session)

            # Done
            yield "event: done\ndata: {}\n\n"

        except Exception as e:
            error_id = uuid.uuid4().hex[:8]
            logger.error(f"Stream error [{error_id}]: {e}")
            yield f"event: error\ndata: internal_error:{error_id}\n\n"

    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@app.post("/session/clear")
async def clear_session(user_id: str, authorized: bool = Depends(verify_admin_token)):
    """Clear user session (admin only)"""
    success = await session_manager.clear_session(user_id)
    return {"success": success, "user_id": user_id}


@app.get("/sessions")
async def list_sessions(authorized: bool = Depends(verify_admin_token)):
    """List active sessions (admin only)"""
    sessions = []
    for user_id, session in session_manager._sessions.items():
        sessions.append({
            "user_id": user_id,
            "session_id": session.session_id,
            "message_count": len(session.chat.history),
            "created_at": session.created_at.isoformat(),
            "last_activity": session.last_activity.isoformat()
        })
    return {"sessions": sessions, "count": len(sessions)}


# =============================================================================
# HISTORY RETRIEVAL ENDPOINTS (Public - for frontend sidebar)
# =============================================================================

@app.get("/sessions/{user_id}")
async def get_user_sessions(user_id: str):
    """
    Get user's conversation sessions for sidebar display.
    
    Returns list of sessions with title and metadata.
    """
    # Validate user_id format
    if not re.match(r'^[a-zA-Z0-9_-]+$', user_id):
        raise HTTPException(status_code=400, detail="Invalid user_id format")
    
    sessions = await conversation_store.get_user_sessions(user_id, limit=20)
    return {"sessions": sessions}


@app.get("/session/{session_id}/history")
async def get_session_history(session_id: str):
    """
    Get message history for a specific session.
    
    Returns formatted messages ready for frontend rendering.
    """
    # Validate session_id format
    if not re.match(r'^[a-zA-Z0-9_-]+$', session_id):
        raise HTTPException(status_code=400, detail="Invalid session_id format")
    
    messages = await conversation_store.get_session_history(session_id)
    return {"messages": messages, "session_id": session_id}


# =============================================================================
# PRIVACY CONTROLS (GDPR Compliance)
# =============================================================================

@app.delete("/user/{user_id}/data")
async def delete_user_data(user_id: str):
    """
    Delete all user data (GDPR Right to Erasure).
    
    Removes:
    - All conversation history
    - User profile and preferences
    - Active sessions from memory
    """
    # Validate user_id format
    if not re.match(r'^[a-zA-Z0-9_-]+$', user_id):
        raise HTTPException(status_code=400, detail="Invalid user_id format")
    
    try:
        # Delete all conversations
        deleted_sessions = await conversation_store.clear_user_sessions(user_id)
        
        # Delete user profile
        deleted_user = await user_store.delete_user(user_id)
        
        # Clear from memory cache
        if session_manager:
            # Remove any cached sessions for this user
            keys_to_remove = [k for k in session_manager._sessions.keys() 
                           if k == user_id or k.startswith(f"{user_id}_")]
            for key in keys_to_remove:
                session_manager._sessions.pop(key, None)
        
        logger.info(f"Deleted data for user {user_id}: {deleted_sessions} sessions")
        
        return {
            "success": True,
            "deleted_sessions": deleted_sessions,
            "deleted_profile": deleted_user,
            "message": "ყველა მონაცემი წაიშალა"
        }
    except Exception as e:
        logger.error(f"Error deleting user data: {e}")
        raise HTTPException(status_code=500, detail="Failed to delete user data")


# =============================================================================
# RUN
# =============================================================================

if __name__ == "__main__":
    import uvicorn

    # Question #5: Cloud Run Compatibility
    # - Set PORT env var for Cloud Run
    # - Use 0.0.0.0 host
    # - Consider min_instances=1 to avoid cold starts

    uvicorn.run(
        "main:app",
        host=settings.host,
        port=int(os.environ.get("PORT", settings.port)),
        reload=settings.debug
    )

# Changelog - Memory Optimization 2026

All notable changes to the memory system will be documented here.

---

## [Week 1] - 2026-01-13

### Fixed

#### üêõ Summary Injection Bug
- **Issue**: Summary was logged but never passed to Gemini model
- **Location**: `main.py:292-294`
- **Fix**: Prepend summary as context message in history
- **Impact**: AI can now actually recall summarized conversations

**Before**:
```python
if summary and not history:
    logger.info(f"Injecting summary...")  # Does nothing!
```

**After**:
```python
if summary:
    summary_message = {
        "role": "user",
        "parts": [{"text": f"[·É¨·Éò·Éú·Éê ·É°·Éê·É£·Éë·É†·Éò·É° ·Éô·Éù·Éú·É¢·Éî·É•·É°·É¢·Éò: {summary}]"}]
    }
    gemini_history = [summary_message] + gemini_history
```

### Changed

#### üì¶ Summary Retention Extended
- **Schema Update**: Added `summary_expires_at` field
- **TTL Change**: 7 days ‚Üí 30 days for summaries
- **Rationale**: Summaries are cheap (~500 tokens) vs raw history (~20k tokens)
- **Files Modified**:
  - `app/memory/mongo_store.py` (schema, indexes)
  - `scripts/migrate_summary_ttl.py` (new migration script)

### Added

#### üìÑ New Files
- `CHANGELOG.md` - This file
- `scripts/migrate_summary_ttl.py` - Database migration for TTL update
- `docs/WEEK_1_VERIFICATION.md` - Testing procedures

---

## [Week 4] - 2026-01-13

### Added

#### Context Caching for 85% Token Savings
- **New Module**: `app/cache/context_cache.py`
  - `ContextCacheManager` - Manages Gemini cached content
  - `CacheRefreshTask` - Background task for auto-refresh
  - `CacheMetrics` - Tracks hits, misses, and cost savings

#### New API Endpoints
- `GET /cache/metrics` - View cache statistics (admin)
- `POST /cache/refresh` - Manual cache refresh (admin)
- Updated `/health` to include cache status

#### Configuration Options
```bash
ENABLE_CONTEXT_CACHING=true
CONTEXT_CACHE_TTL_MINUTES=60
CACHE_REFRESH_BEFORE_EXPIRY_MINUTES=10
CACHE_CHECK_INTERVAL_MINUTES=5
```

### Changed

#### SessionManager Updated
- **Location**: `main.py:241-330`
- Now accepts optional `cache_manager` parameter
- Uses `cached_content` when cache is valid
- Falls back to full system instruction if cache unavailable

#### CatalogLoader Enhanced
- **Location**: `app/catalog/loader.py`
- Added `initialize_context_cache()` method
- Added `refresh_context_cache()` method
- Removed deprecated old SDK caching methods

### Technical Details

**Cached Content**:
- System prompt: ~5,000 tokens
- Product catalog: ~60,000 tokens
- Total cached: ~65,000 tokens

**Cost Savings**:
- Before: $0.075/1M input tokens
- After: $0.01875/1M cached tokens (75% discount)
- Estimated monthly savings: $306

### Safety
- Full backward compatibility with Weeks 1-3
- Graceful degradation if cache fails
- No changes to summarization or memory systems

---

## [Week 3] - Completed

### Added
- `ConversationSummarizer` class for LLM-based summaries
- Semantic understanding replaces keyword extraction
- Fallback to simple summary if LLM fails

---

## [Week 2] - Completed

### Changed
- Migrated from `google.generativeai` to `google.genai` SDK
- Updated all imports and model initialization
- Fixed async/sync issues with tool functions

---

---

## Migration Notes

### Week 1 ‚Üí Production
- Run `python scripts/migrate_summary_ttl.py` before deployment
- No breaking changes, backward compatible
- Monitor MongoDB TTL index creation

---

**Format**: Based on [Keep a Changelog](https://keepachangelog.com/)
